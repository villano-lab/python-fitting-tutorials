{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Types of Error\n",
    "\n",
    "In the first notebook, we created some fake data with gaussian/normal noise as error.\n",
    "Let's take a look at how that error affects the outcome of our fit (aside from just changing the uncertainties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import lmfit as lf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We'll start with a similar setup to our original as a sort of control for our experiment. \n",
    "The code will look roughly the same, but I haven't made it runnable because I want to reorganize it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Setup - y = f(x) = x^2\n",
    "\n",
    "#Fakedata\n",
    "xdata = np.linspace(0,5,50)                \n",
    "g_ydata = np.zeros(len(xdata))              #Adding the \"c\" prefix to indicate \"gaussian\"\n",
    "g_noise = np.random.normal(0,1,len(xdata))  \n",
    "for i,n in enumerate(xdata):\n",
    "    c_ydata[i] = n**2+c_noise[i]\n",
    "g_sigdata = np.ones(len(xdata))\n",
    "g_weighdata = 1/c_sigdata\n",
    "\n",
    "#Function\n",
    "def f(x,a,b,c):  \n",
    "    return a*x**2+b*x+c\n",
    "\n",
    "#Points representing function\n",
    "ycurve = xdata**2\n",
    "\n",
    "#Setup\n",
    "l_mod = lf.Model(f)\n",
    "params = l_mod.make_params(a=1, b=0, c=0)\n",
    "\n",
    "#Do fit\n",
    "l_fit = l_mod.fit(c_ydata, params, x=xdata, weights=c_weighdata)\n",
    "\n",
    "#Define Stuff\n",
    "l_dict = l_fit.best_values\n",
    "l_a = l_dict['a']\n",
    "l_b = l_dict['b']\n",
    "l_c = l_dict['c']\n",
    "\n",
    "#Create array to plot\n",
    "g_curve = l_a*xdata**2+l_b*xdata+l_c\n",
    "\n",
    "#I'm not worried about the numeric ouput right now, so I removed l_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do something a bit different this time, however.\n",
    "I've already seen this curve, so that's not really what I'm after here.\n",
    "What I'd like to see is what happens if I run this code several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run once:\n",
    "xdata = np.linspace(0,5,50)\n",
    "g_ydata = np.zeros(len(xdata))\n",
    "def f(x,a,b,c):  \n",
    "    return a*x**2+b*x+c\n",
    "ycurve = xdata**2\n",
    "l_mod = lf.Model(f)\n",
    "params = l_mod.make_params(a=1, b=0, c=0)\n",
    "a = np.zeros(1000)    #Make empty arrays to define later.\n",
    "b = np.zeros(len(a))\n",
    "c = np.zeros(len(a))\n",
    "a_bins = np.linspace(0.75,1.25,50)  #An array centered on the expected value for a.\n",
    "b_bins = np.linspace(-1,1,50) #With room on each side for error.\n",
    "c_bins = np.linspace(-1,1,50) #And a decent length for our plot.\n",
    "\n",
    "#Run many times:\n",
    "i = 0\n",
    "while i < len(a): #This will run as many times as there are elements in a.\n",
    "    g_noise = np.random.normal(0,1,len(xdata))  \n",
    "    for j,n in enumerate(xdata):\n",
    "        g_ydata[j] = n**2+g_noise[j]\n",
    "    g_sigdata = np.ones(len(xdata))\n",
    "    g_weighdata = 1/g_sigdata\n",
    "    l_fit = l_mod.fit(g_ydata, params, x=xdata, weights=g_weighdata)\n",
    "    l_dict = l_fit.best_values\n",
    "    l_a = l_dict['a']\n",
    "    a[i] = l_a        #Make the ith entry in a equal to the a we found for the ith run.\n",
    "    l_b = l_dict['b']\n",
    "    b[i] = l_b\n",
    "    l_c = l_dict['c']\n",
    "    c[i] = l_c\n",
    "    i += 1\n",
    "    \n",
    "#Save a curve from average:\n",
    "g_curve = np.mean(a)*xdata**2+np.mean(b)*xdata+np.mean(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how these value distributions look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.subplot(111)             #This will allow us to create multiple, separate plots.\n",
    "plt.hist(a,bins=a_bins)      #The bins sort similar values together.\n",
    "plt.title('Distribution: a') #Title the plot\n",
    "plt.xlabel('Value')          #Label the x-axis\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(a))) #Below the plot, print the average value of a that we fitted for.\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(b,bins=b_bins)      #Without grouping similar values, we would probably have only one occurrence for each\n",
    "plt.title('Distribution: b')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(b)))\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(c,bins=c_bins)      #The bins also happen to determine the range over which we plot.\n",
    "plt.title('Distribution: c')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect, but these outputs are reasonably symmetric, and we can tell where the peaks would be. \n",
    "They also taper off quite nicely. So, we can reasonably assume that our fit will tend toward the correct values.\n",
    "And, if we take a look at our averages for each array, they're similar to the expected values!\n",
    "\n",
    "If you want to check the regions outside of what's visible in these plots, feel free to change the ranges on the bin arrays. \n",
    "(For example, you could plot from b = -2 to 2 by setting b_bin=np.linspace(-2,2,100).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Gaussian Error\n",
    "\n",
    "What happens to our values if our error isn't gaussian?\n",
    "There are a few cases where this might occur:\n",
    "- The probability doesn't taper off as quickly as a gaussian's, so we are more likely to have outliers.\n",
    "- We are more likely to have error that gives us higher values than lower values, or vice versa.\n",
    "\n",
    "Let's do the same plot with another noise distribution, the Standard Cauchy Distribution.</br>\n",
    "Like the gaussian above, the error is centered on zero. \n",
    "The thing most analogous to the width is set to be 1, so we should have settings that are roughly analogous to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup - run once:\n",
    "#xdata was already defined, so I've removed it here.\n",
    "c_ydata = np.zeros(len(xdata)) #I've used the \"c\" prefix to indicate \"Cauchy\"\n",
    "#f, ycurve, lmod, and params were already defined, so I've removed them here.\n",
    "#a, b, c, and their bins are already defined, so I've removed them here.\n",
    "\n",
    "#Setup - loop:\n",
    "i = 0\n",
    "while i < len(a):\n",
    "    c_noise = np.random.standard_cauchy(len(xdata)) #This distribution won't vanish as quickly as the gaussian does at its extremes.\n",
    "    for j,n in enumerate(xdata):\n",
    "        c_ydata[j] = n**2+c_noise[j]\n",
    "    c_sigdata = np.ones(len(xdata))\n",
    "    c_weighdata = 1/c_sigdata\n",
    "    l_fit = l_mod.fit(c_ydata, params, x=xdata, weights=c_weighdata)\n",
    "    l_dict = l_fit.best_values\n",
    "    l_a = l_dict['a']\n",
    "    a[i] = l_a       #We're overwriting a here because we won't need the old one again.\n",
    "    l_b = l_dict['b']\n",
    "    b[i] = l_b\n",
    "    l_c = l_dict['c']\n",
    "    c[i] = l_c\n",
    "    i += 1\n",
    "\n",
    "#Save a curve from average:\n",
    "c_curve = np.mean(a)*xdata**2+np.mean(b)*xdata+np.mean(c)\n",
    "    \n",
    "#Plotting\n",
    "plt.subplot(111)\n",
    "plt.hist(a,bins=a_bins)\n",
    "plt.title('Distribution: a')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(b,bins=b_bins)\n",
    "plt.title('Distribution: b')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(c,bins=c_bins)\n",
    "plt.title('Distribution: c')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the range of values must be greater. This makes sense given that the distribution has wider tails.\n",
    "Let's try to find a range that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New bins\n",
    "a_bins = np.linspace(-1,3,50)\n",
    "b_bins = np.linspace(-6,6,50)\n",
    "c_bins = np.linspace(-7,7,50)\n",
    "\n",
    "#Plotting\n",
    "plt.subplot(111)\n",
    "plt.hist(a,bins=a_bins)             #Removing \"bins=str\" allows python to auto-assign.\n",
    "plt.title('Distribution: a')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(a)))\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(b,bins=b_bins)\n",
    "plt.title('Distribution: b')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(b)))\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(c,bins=c_bins)\n",
    "plt.title('Distribution: c')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ranges are *much* wider than they were for the gaussian.\n",
    "Not only that, but you may notice -- depending on your luck -- that the averages aren't good.</br>\n",
    "(When I ran this, I got a = 0.5, b = 3, and c = -2.5. Our expected values are a = 1, b = 0, c = 0. Those are way off, despite us having 1000 runs of fake data!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed Distribution\n",
    "\n",
    "Now let's take a look at the case where our noise is skewed.\n",
    "We will, again, make our distribution otherwise as analogous to our existing distributions as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup - run once:\n",
    "s_ydata = np.zeros(len(xdata)) #I've used the \"s\" prefix to indicate \"skewed\"\n",
    "\n",
    "#Setup - loop:\n",
    "i = 0\n",
    "while i < len(a):\n",
    "    s_noise = stat.skewnorm.rvs(1,size=len(xdata)) #This distribution will be skewed toward higher values.\n",
    "    for j,n in enumerate(xdata):\n",
    "        s_ydata[j] = n**2+s_noise[j]\n",
    "    s_sigdata = np.ones(len(xdata))\n",
    "    s_weighdata = 1/s_sigdata\n",
    "    l_fit = l_mod.fit(s_ydata, params, x=xdata, weights=s_weighdata)\n",
    "    l_dict = l_fit.best_values\n",
    "    l_a = l_dict['a']\n",
    "    a[i] = l_a       #We're overwriting a here because we won't need the old one again.\n",
    "    l_b = l_dict['b']\n",
    "    b[i] = l_b\n",
    "    l_c = l_dict['c']\n",
    "    c[i] = l_c\n",
    "    i += 1\n",
    "\n",
    "#Save a curve from average:\n",
    "s_curve = np.mean(a)*xdata**2+np.mean(b)*xdata+np.mean(c)\n",
    "    \n",
    "#New bins\n",
    "a_bins = np.linspace(0.5,1.5,50)\n",
    "b_bins = np.linspace(-1,1,50)\n",
    "c_bins = np.linspace(-1,1.5,50)\n",
    "\n",
    "#Plotting\n",
    "plt.subplot(111)\n",
    "plt.hist(a,bins=a_bins)\n",
    "plt.title('Distribution: a')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(a)))\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(b,bins=b_bins)\n",
    "plt.title('Distribution: b')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(b)))\n",
    "\n",
    "plt.subplot(111)\n",
    "plt.hist(c,bins=c_bins)\n",
    "plt.title('Distribution: c')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "print(\"Average: \"+str(np.mean(c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our parameters a and b don't look too bad. \n",
    "They have roughly the same range that was used for the gaussian fit, well-centered, and somewhat symmetric.\n",
    "The parameter c also looks like it has a roughly defined center, and that distribution is symmetric as well.\n",
    "However, while a and b are close to their true values, c is pretty far off.\n",
    "This makes sense give that c is the vertical offset of the function, \n",
    "while a and b have to do with how the function scales relative to x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "\n",
    "We have what should be roughly the same sets of data with different types of error.\n",
    "Let's plot for a visual side-by-side comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "fig = plt.figure(figsize=(9.0,8.0))\n",
    "\n",
    "plt.plot(xdata,ycurve,color='black',label='True Function')\n",
    "plt.plot(xdata,g_curve,color='yellow',linestyle='-.',label='Gaussian') #Formatted differently for visibility of ycurve\n",
    "plt.plot(xdata,c_curve,linestyle='--',label='Cauchy')\n",
    "plt.plot(xdata,s_curve,linestyle='--',label='Skewed')\n",
    "#plt.plot(xdata,g_ydata,'bo',label='Data (Gaussian Noise)') #Uncomment any of these to see the data\n",
    "#plt.plot(xdata,c_ydata,'bo',label='Data (Cauchy Noise)')\n",
    "#plt.plot(xdata,s_ydata,'bo',label='Data (Skewed Noise)')\n",
    "plt.title('y = f(x) = x\\u00b2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With many data runs, our gaussian-error fit is right on top of the true function.\n",
    "The skewed-error fit rests just above them and has a very similar shape.\n",
    "Our Cauchy-error fit is not correct at all.\n",
    "\n",
    "So what's the solution? With real data, we typically can't control what our uncertainties look like.\n",
    "Least-squares can only use gaussian error, so we'll have to look into other methods next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
